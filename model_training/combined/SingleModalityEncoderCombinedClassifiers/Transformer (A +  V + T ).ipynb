{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b3dcdc5-b870-49e6-9e16-fa730cb809bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e366f31-2c1b-46af-b3c6-039b01fc6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, base_path, split, bert_feature_size='bert_text_features_128'):\n",
    "        \"\"\"\n",
    "        Initialize the dataset by loading the tensor files.\n",
    "\n",
    "        :param base_path: The path where the .pt files are stored\n",
    "        :param split: The data split to load ('train', 'validate', or 'test')\n",
    "        :param bert_feature_size: The size of the BERT features to load\n",
    "        \"\"\"\n",
    "        self.audio_features = torch.load(f'{base_path}/{split}_audio_features.pt')\n",
    "        self.facial_features = torch.load(f'{base_path}/{split}_facial_features.pt')\n",
    "        self.bert_features = torch.load(f'{base_path}/{split}_{bert_feature_size}.pt')\n",
    "        self.labels = torch.load(f'{base_path}/{split}_labels.pt')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'audio_features': self.audio_features[idx],\n",
    "            'facial_features': self.facial_features[idx],\n",
    "            'bert_features': self.bert_features[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b922167-9a34-4fec-9c52-b49b51e46c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the data is saved in './tensor_data' directory\n",
    "base_path = './tensor_data'\n",
    "bert_feature_size = 'bert_text_features_512'  # or 256, 128 based on what is needed\n",
    "\n",
    "train_dataset = MultimodalDataset(base_path, 'train', bert_feature_size)\n",
    "val_dataset = MultimodalDataset(base_path, 'validate', bert_feature_size)\n",
    "\n",
    "# These dataloaders can be passed directly to the ModelTrainer class\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b85af2a2-69ab-40be-9d20-e690026afa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model, train_dataset, val_dataset, model_name, epochs, save_interval, lr=1e-3, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.model_name = model_name\n",
    "        self.start_epoch = 0\n",
    "        self.epochs = epochs\n",
    "        self.save_interval = save_interval\n",
    "        self.lr = lr\n",
    "        self.device = device\n",
    "        self.history = defaultdict(list)\n",
    "        self.checkpoint_dir = f'modelCheckPoints/{self.model_name}'\n",
    "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def save_checkpoint(self, epoch):\n",
    "        state = {'epoch': epoch, 'state_dict': self.model.state_dict()}\n",
    "        torch.save(state, f'{self.checkpoint_dir}/{epoch}.pt')\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        checkpoints = [ckpt for ckpt in os.listdir(self.checkpoint_dir) if ckpt.endswith('.pt')]\n",
    "        if checkpoints:\n",
    "            latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('.')[0]))\n",
    "            checkpoint = torch.load(f'{self.checkpoint_dir}/{latest_checkpoint}', map_location=self.device)\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            self.start_epoch = checkpoint['epoch'] + 1\n",
    "            print(f\"Loaded checkpoint: {latest_checkpoint} at epoch {checkpoint['epoch']}\")\n",
    "        else:\n",
    "            print(\"No checkpoints found, starting from scratch.\")\n",
    "\n",
    "    def save_history(self):\n",
    "        with open(f'{self.checkpoint_dir}/history.json', 'w') as f:\n",
    "            json.dump(self.history, f)\n",
    "\n",
    "    def train_one_epoch(self, dataloader, criterion, max_grad_norm=1.0):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "    \n",
    "        for batch in dataloader:\n",
    "            audio = batch['audio'].to(self.device)\n",
    "            vision = batch['vision'].to(self.device)\n",
    "            text_bert = batch['text_bert'].to(self.device)\n",
    "            labels = batch['label'].to(self.device)\n",
    "    \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(audio, vision, text_bert)\n",
    "    \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_grad_norm)\n",
    "            self.optimizer.step()\n",
    "    \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        accuracy = correct_predictions / len(dataloader.dataset)\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def validate(self, dataloader, criterion):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                audio = batch['audio'].to(self.device)\n",
    "                vision = batch['vision'].to(self.device)\n",
    "                text_bert = batch['text_bert'].to(self.device)\n",
    "                labels = batch['label'].to(self.device)\n",
    "    \n",
    "                outputs = self.model(audio, vision, text_bert)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        accuracy = correct_predictions / len(dataloader.dataset)\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def train(self, criterion):\n",
    "        self.load_checkpoint()\n",
    "        train_dataloader = DataLoader(self.train_dataset, batch_size=256, shuffle=True)\n",
    "        val_dataloader = DataLoader(self.val_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "        for epoch in range(self.start_epoch, self.epochs):\n",
    "            train_loss, train_acc = self.train_one_epoch(train_dataloader, criterion)\n",
    "            val_loss, val_acc = self.validate(val_dataloader, criterion)\n",
    "    \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "    \n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "            if (epoch + 1) % self.save_interval == 0:\n",
    "                self.save_checkpoint(epoch + 1)\n",
    "    \n",
    "            self.save_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7baa2c1d-38ba-4f65-90f9-e5498b7ce8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalAttentionClassifier(nn.Module):\n",
    "    def __init__(self, audio_feature_dim, facial_feature_dim, bert_feature_dim, num_classes, nhead, num_encoder_layers, dim_feedforward, dropout=0.1):\n",
    "        super(MultimodalAttentionClassifier, self).__init__()\n",
    "\n",
    "        # Original total feature dimension\n",
    "        original_total_dim = audio_feature_dim + facial_feature_dim + bert_feature_dim\n",
    "\n",
    "        # Find a new total dimension that is divisible by the number of heads\n",
    "        # This is a simple approach: you might want to fine-tune this depending on your model's needs\n",
    "        transformer_dim = original_total_dim + (nhead - (original_total_dim % nhead)) if original_total_dim % nhead != 0 else original_total_dim\n",
    "\n",
    "        self.embedding = nn.Linear(original_total_dim, transformer_dim)\n",
    "\n",
    "        # Transformer Encoder Layer\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=transformer_dim, nhead=nhead,\n",
    "                                                dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(transformer_dim, num_classes)\n",
    "\n",
    "    def forward(self, audio_features, facial_features, bert_features):\n",
    "        # Concatenate all features\n",
    "        combined_features = torch.cat((audio_features, facial_features, bert_features), dim=1)\n",
    "\n",
    "        # Embedding the input features to match transformer dimension\n",
    "        embedded_features = self.embedding(combined_features).unsqueeze(1)  # Add sequence dimension\n",
    "\n",
    "        # Transformer encoder\n",
    "        transformed_features = self.transformer_encoder(embedded_features).squeeze(1)\n",
    "\n",
    "        # Classification\n",
    "        logits = self.classifier(transformed_features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b80e848-4688-49f0-8d89-ebcc5fee76f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 2048 768\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_dataloader is already defined and loads the correct dataset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Get a single batch to infer feature dimensions\n",
    "sample_batch = next(iter(train_dataloader))\n",
    "audio_feature_dim = sample_batch['audio_features'].shape[1]\n",
    "facial_feature_dim = sample_batch['facial_features'].shape[1]\n",
    "bert_feature_dim = sample_batch['bert_features'].shape[1]\n",
    "\n",
    "print(audio_feature_dim,facial_feature_dim,bert_feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8341689-63e1-4cf6-8313-43351bf4b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoints found, starting from scratch.\n",
      "Epoch 1/100, Train Loss: 0.0172, Train Accuracy: 0.3256, Val Loss: 0.0087, Val Accuracy: 0.3364\n",
      "Epoch 2/100, Train Loss: 0.0089, Train Accuracy: 0.3329, Val Loss: 0.0087, Val Accuracy: 0.3371\n",
      "Epoch 3/100, Train Loss: 0.0088, Train Accuracy: 0.3322, Val Loss: 0.0087, Val Accuracy: 0.3371\n",
      "Epoch 4/100, Train Loss: 0.0089, Train Accuracy: 0.3262, Val Loss: 0.0090, Val Accuracy: 0.3364\n",
      "Epoch 5/100, Train Loss: 0.0090, Train Accuracy: 0.3316, Val Loss: 0.0087, Val Accuracy: 0.3371\n",
      "Epoch 6/100, Train Loss: 0.0088, Train Accuracy: 0.3343, Val Loss: 0.0090, Val Accuracy: 0.3371\n",
      "Epoch 7/100, Train Loss: 0.0088, Train Accuracy: 0.3269, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 8/100, Train Loss: 0.0088, Train Accuracy: 0.3324, Val Loss: 0.0093, Val Accuracy: 0.3364\n",
      "Epoch 9/100, Train Loss: 0.0089, Train Accuracy: 0.3344, Val Loss: 0.0088, Val Accuracy: 0.3364\n",
      "Epoch 10/100, Train Loss: 0.0089, Train Accuracy: 0.3217, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 11/100, Train Loss: 0.0088, Train Accuracy: 0.3352, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 12/100, Train Loss: 0.0088, Train Accuracy: 0.3287, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 13/100, Train Loss: 0.0088, Train Accuracy: 0.3382, Val Loss: 0.0089, Val Accuracy: 0.3264\n",
      "Epoch 14/100, Train Loss: 0.0088, Train Accuracy: 0.3328, Val Loss: 0.0088, Val Accuracy: 0.3371\n",
      "Epoch 15/100, Train Loss: 0.0089, Train Accuracy: 0.3303, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 16/100, Train Loss: 0.0088, Train Accuracy: 0.3293, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 17/100, Train Loss: 0.0087, Train Accuracy: 0.3300, Val Loss: 0.0087, Val Accuracy: 0.3364\n",
      "Epoch 18/100, Train Loss: 0.0087, Train Accuracy: 0.3366, Val Loss: 0.0089, Val Accuracy: 0.3371\n",
      "Epoch 19/100, Train Loss: 0.0088, Train Accuracy: 0.3322, Val Loss: 0.0087, Val Accuracy: 0.3371\n",
      "Epoch 20/100, Train Loss: 0.0088, Train Accuracy: 0.3365, Val Loss: 0.0087, Val Accuracy: 0.3371\n",
      "Epoch 21/100, Train Loss: 0.0088, Train Accuracy: 0.3301, Val Loss: 0.0087, Val Accuracy: 0.3364\n",
      "Epoch 22/100, Train Loss: 0.0088, Train Accuracy: 0.3383, Val Loss: 0.0088, Val Accuracy: 0.3364\n",
      "Epoch 23/100, Train Loss: 0.0088, Train Accuracy: 0.3428, Val Loss: 0.0087, Val Accuracy: 0.3364\n",
      "Epoch 24/100, Train Loss: 0.0087, Train Accuracy: 0.3365, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 25/100, Train Loss: 0.0087, Train Accuracy: 0.3305, Val Loss: 0.0088, Val Accuracy: 0.3264\n",
      "Epoch 26/100, Train Loss: 0.0087, Train Accuracy: 0.3369, Val Loss: 0.0088, Val Accuracy: 0.3371\n",
      "Epoch 27/100, Train Loss: 0.0088, Train Accuracy: 0.3313, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 28/100, Train Loss: 0.0087, Train Accuracy: 0.3287, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 29/100, Train Loss: 0.0087, Train Accuracy: 0.3315, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 30/100, Train Loss: 0.0087, Train Accuracy: 0.3296, Val Loss: 0.0088, Val Accuracy: 0.3364\n",
      "Epoch 31/100, Train Loss: 0.0087, Train Accuracy: 0.3306, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 32/100, Train Loss: 0.0087, Train Accuracy: 0.3310, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 33/100, Train Loss: 0.0087, Train Accuracy: 0.3327, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 34/100, Train Loss: 0.0087, Train Accuracy: 0.3345, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 35/100, Train Loss: 0.0087, Train Accuracy: 0.3377, Val Loss: 0.0087, Val Accuracy: 0.3364\n",
      "Epoch 36/100, Train Loss: 0.0087, Train Accuracy: 0.3393, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 37/100, Train Loss: 0.0087, Train Accuracy: 0.3228, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 38/100, Train Loss: 0.0087, Train Accuracy: 0.3352, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 39/100, Train Loss: 0.0087, Train Accuracy: 0.3433, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 40/100, Train Loss: 0.0087, Train Accuracy: 0.3337, Val Loss: 0.0087, Val Accuracy: 0.3364\n",
      "Epoch 41/100, Train Loss: 0.0087, Train Accuracy: 0.3312, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 42/100, Train Loss: 0.0087, Train Accuracy: 0.3392, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 43/100, Train Loss: 0.0087, Train Accuracy: 0.3330, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 44/100, Train Loss: 0.0087, Train Accuracy: 0.3314, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 45/100, Train Loss: 0.0087, Train Accuracy: 0.3309, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 46/100, Train Loss: 0.0087, Train Accuracy: 0.3437, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 47/100, Train Loss: 0.0087, Train Accuracy: 0.3419, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 48/100, Train Loss: 0.0087, Train Accuracy: 0.3363, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 49/100, Train Loss: 0.0087, Train Accuracy: 0.3371, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 50/100, Train Loss: 0.0087, Train Accuracy: 0.3384, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 51/100, Train Loss: 0.0087, Train Accuracy: 0.3309, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 52/100, Train Loss: 0.0087, Train Accuracy: 0.3252, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 53/100, Train Loss: 0.0087, Train Accuracy: 0.3321, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 54/100, Train Loss: 0.0087, Train Accuracy: 0.3273, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 55/100, Train Loss: 0.0087, Train Accuracy: 0.3255, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 56/100, Train Loss: 0.0087, Train Accuracy: 0.3238, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 57/100, Train Loss: 0.0087, Train Accuracy: 0.3312, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 58/100, Train Loss: 0.0087, Train Accuracy: 0.3337, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 59/100, Train Loss: 0.0087, Train Accuracy: 0.3371, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 60/100, Train Loss: 0.0087, Train Accuracy: 0.3338, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 61/100, Train Loss: 0.0087, Train Accuracy: 0.3297, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 62/100, Train Loss: 0.0087, Train Accuracy: 0.3376, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 63/100, Train Loss: 0.0087, Train Accuracy: 0.3345, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 64/100, Train Loss: 0.0087, Train Accuracy: 0.3373, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 65/100, Train Loss: 0.0087, Train Accuracy: 0.3306, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 66/100, Train Loss: 0.0087, Train Accuracy: 0.3358, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 67/100, Train Loss: 0.0087, Train Accuracy: 0.3261, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 68/100, Train Loss: 0.0087, Train Accuracy: 0.3365, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 69/100, Train Loss: 0.0087, Train Accuracy: 0.3405, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 70/100, Train Loss: 0.0087, Train Accuracy: 0.3309, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 71/100, Train Loss: 0.0087, Train Accuracy: 0.3289, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 72/100, Train Loss: 0.0087, Train Accuracy: 0.3389, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 73/100, Train Loss: 0.0087, Train Accuracy: 0.3392, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 74/100, Train Loss: 0.0087, Train Accuracy: 0.3341, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 75/100, Train Loss: 0.0087, Train Accuracy: 0.3345, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 76/100, Train Loss: 0.0087, Train Accuracy: 0.3340, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 77/100, Train Loss: 0.0087, Train Accuracy: 0.3380, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 78/100, Train Loss: 0.0087, Train Accuracy: 0.3379, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 79/100, Train Loss: 0.0087, Train Accuracy: 0.3322, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 80/100, Train Loss: 0.0087, Train Accuracy: 0.3385, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 81/100, Train Loss: 0.0087, Train Accuracy: 0.3345, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 82/100, Train Loss: 0.0087, Train Accuracy: 0.3395, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 83/100, Train Loss: 0.0087, Train Accuracy: 0.3398, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 84/100, Train Loss: 0.0087, Train Accuracy: 0.3321, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 85/100, Train Loss: 0.0087, Train Accuracy: 0.3344, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 86/100, Train Loss: 0.0087, Train Accuracy: 0.3345, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 87/100, Train Loss: 0.0087, Train Accuracy: 0.3356, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 88/100, Train Loss: 0.0087, Train Accuracy: 0.3274, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 89/100, Train Loss: 0.0087, Train Accuracy: 0.3296, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 90/100, Train Loss: 0.0087, Train Accuracy: 0.3319, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 91/100, Train Loss: 0.0087, Train Accuracy: 0.3414, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 92/100, Train Loss: 0.0087, Train Accuracy: 0.3314, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 93/100, Train Loss: 0.0087, Train Accuracy: 0.3304, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 94/100, Train Loss: 0.0087, Train Accuracy: 0.3272, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 95/100, Train Loss: 0.0087, Train Accuracy: 0.3345, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 96/100, Train Loss: 0.0087, Train Accuracy: 0.3324, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 97/100, Train Loss: 0.0087, Train Accuracy: 0.3353, Val Loss: 0.0086, Val Accuracy: 0.3371\n",
      "Epoch 98/100, Train Loss: 0.0087, Train Accuracy: 0.3301, Val Loss: 0.0086, Val Accuracy: 0.3364\n",
      "Epoch 99/100, Train Loss: 0.0087, Train Accuracy: 0.3368, Val Loss: 0.0086, Val Accuracy: 0.3264\n",
      "Epoch 100/100, Train Loss: 0.0087, Train Accuracy: 0.3295, Val Loss: 0.0086, Val Accuracy: 0.3364\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = MultimodalAttentionClassifier(\n",
    "    audio_feature_dim=audio_feature_dim,\n",
    "    facial_feature_dim=facial_feature_dim,\n",
    "    bert_feature_dim=bert_feature_dim,\n",
    "    num_classes=3,  # Assuming 3 classes for classification\n",
    "    nhead=8,  # Number of attention heads\n",
    "    num_encoder_layers=6,  # Number of transformer encoder layers\n",
    "    dim_feedforward=2048  # Dimension of feedforward network in transformer\n",
    ")\n",
    "\n",
    "# Assuming you have a criterion and other parameters defined for ModelTrainer\n",
    "epochs = 100\n",
    "save_interval = 5\n",
    "model_name = \"multimodal_attention_classifier\"\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "trainer.lr = 0.01 \n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = ModelTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    model_name=model_name,\n",
    "    epochs=epochs,\n",
    "    save_interval=save_interval\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8dbcf3e-03c9-49d4-9a42-dc43334c41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoints found, starting from scratch.\n",
      "Epoch 1/100, Train Loss: 0.0262, Train Accuracy: 0.3269, Val Loss: 0.0083, Val Accuracy: 0.3264\n",
      "Epoch 2/100, Train Loss: 0.0052, Train Accuracy: 0.3306, Val Loss: 0.0051, Val Accuracy: 0.3364\n",
      "Epoch 3/100, Train Loss: 0.0045, Train Accuracy: 0.3239, Val Loss: 0.0048, Val Accuracy: 0.3264\n",
      "Epoch 4/100, Train Loss: 0.0045, Train Accuracy: 0.3393, Val Loss: 0.0047, Val Accuracy: 0.3364\n",
      "Epoch 5/100, Train Loss: 0.0044, Train Accuracy: 0.3369, Val Loss: 0.0048, Val Accuracy: 0.3264\n",
      "Epoch 6/100, Train Loss: 0.0045, Train Accuracy: 0.3286, Val Loss: 0.0049, Val Accuracy: 0.3371\n",
      "Epoch 7/100, Train Loss: 0.0045, Train Accuracy: 0.3283, Val Loss: 0.0051, Val Accuracy: 0.3371\n",
      "Epoch 8/100, Train Loss: 0.0045, Train Accuracy: 0.3290, Val Loss: 0.0047, Val Accuracy: 0.3264\n",
      "Epoch 9/100, Train Loss: 0.0044, Train Accuracy: 0.3293, Val Loss: 0.0048, Val Accuracy: 0.3371\n",
      "Epoch 10/100, Train Loss: 0.0044, Train Accuracy: 0.3329, Val Loss: 0.0049, Val Accuracy: 0.3364\n",
      "Epoch 11/100, Train Loss: 0.0045, Train Accuracy: 0.3323, Val Loss: 0.0048, Val Accuracy: 0.3371\n",
      "Epoch 12/100, Train Loss: 0.0045, Train Accuracy: 0.3287, Val Loss: 0.0048, Val Accuracy: 0.3364\n",
      "Epoch 13/100, Train Loss: 0.0045, Train Accuracy: 0.3336, Val Loss: 0.0047, Val Accuracy: 0.3364\n",
      "Epoch 14/100, Train Loss: 0.0044, Train Accuracy: 0.3331, Val Loss: 0.0049, Val Accuracy: 0.3364\n",
      "Epoch 15/100, Train Loss: 0.0045, Train Accuracy: 0.3415, Val Loss: 0.0048, Val Accuracy: 0.3264\n",
      "Epoch 16/100, Train Loss: 0.0045, Train Accuracy: 0.3322, Val Loss: 0.0048, Val Accuracy: 0.3371\n",
      "Epoch 17/100, Train Loss: 0.0044, Train Accuracy: 0.3333, Val Loss: 0.0048, Val Accuracy: 0.3371\n",
      "Epoch 18/100, Train Loss: 0.0045, Train Accuracy: 0.3402, Val Loss: 0.0047, Val Accuracy: 0.3264\n",
      "Epoch 19/100, Train Loss: 0.0044, Train Accuracy: 0.3372, Val Loss: 0.0050, Val Accuracy: 0.3371\n",
      "Epoch 20/100, Train Loss: 0.0045, Train Accuracy: 0.3296, Val Loss: 0.0047, Val Accuracy: 0.3364\n",
      "Epoch 21/100, Train Loss: 0.0045, Train Accuracy: 0.3321, Val Loss: 0.0047, Val Accuracy: 0.3371\n",
      "Epoch 22/100, Train Loss: 0.0045, Train Accuracy: 0.3303, Val Loss: 0.0047, Val Accuracy: 0.3364\n",
      "Epoch 23/100, Train Loss: 0.0044, Train Accuracy: 0.3390, Val Loss: 0.0050, Val Accuracy: 0.3364\n",
      "Epoch 24/100, Train Loss: 0.0044, Train Accuracy: 0.3284, Val Loss: 0.0048, Val Accuracy: 0.3364\n",
      "Epoch 25/100, Train Loss: nan, Train Accuracy: 0.3352, Val Loss: nan, Val Accuracy: 0.3371\n",
      "Epoch 26/100, Train Loss: nan, Train Accuracy: 0.3368, Val Loss: nan, Val Accuracy: 0.3371\n",
      "Epoch 27/100, Train Loss: nan, Train Accuracy: 0.3368, Val Loss: nan, Val Accuracy: 0.3371\n",
      "Epoch 28/100, Train Loss: nan, Train Accuracy: 0.3368, Val Loss: nan, Val Accuracy: 0.3371\n",
      "Epoch 29/100, Train Loss: nan, Train Accuracy: 0.3368, Val Loss: nan, Val Accuracy: 0.3371\n",
      "Epoch 30/100, Train Loss: nan, Train Accuracy: 0.3368, Val Loss: nan, Val Accuracy: 0.3371\n",
      "\n",
      "Training interrupted by user. Saving last model state...\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = MultimodalAttentionClassifier(\n",
    "    audio_feature_dim=audio_feature_dim,\n",
    "    facial_feature_dim=facial_feature_dim,\n",
    "    bert_feature_dim=bert_feature_dim,\n",
    "    num_classes=3,  # Assuming 3 classes for classification\n",
    "    nhead=8,  # Number of attention heads\n",
    "    num_encoder_layers=6,  # Number of transformer encoder layers\n",
    "    dim_feedforward=2048  # Dimension of feedforward network in transformer\n",
    ")\n",
    "\n",
    "# Assuming you have a criterion and other parameters defined for ModelTrainer\n",
    "epochs = 100\n",
    "save_interval = 5\n",
    "model_name = \"multimodal_attention_classifier2\"\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer2 = ModelTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    model_name=model_name,\n",
    "    epochs=epochs,\n",
    "    save_interval=save_interval,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer2.train(criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
